{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Austen-bot\n",
    "Alan Au\n",
    "2018-05-07\n",
    "\n",
    "This is a simple text generator to produce a \"story\" (I use this loosely) based on _Pride and Prejudice_.\n",
    "\n",
    "In the first section, I'm going to play around with a Markov chain generator, at the word level. It uses Python lists to store the \"first\" words in each sentences, and a hash table to store lists of follow-up words for every word in the text. Note that because I'm using lists to store follow-up words, I get frequency weighting for free. Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "__author__ = 'Alan Au'\n",
    "__date__   = '2018-05-07'\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "For my text data, I used the text of _Pride & Prejudice_ from Project Gutenberg. Note that this version is encoded in UTF-8 and uses different characters for opening and closing quotation marks.\n",
    "\n",
    "It can be found here: http://www.gutenberg.org/files/1342/1342-0.txt\n",
    "\n",
    "First I prepare the data as follows:\n",
    "1. Delete the header and footer, so everything up to \"Chapter 1\" and after \"End of the Project\".\n",
    "2. Lines starting with multiple spaces are skipped, as they interfere with text prediction.\n",
    "3. Trailing newlines are stripped, so each paragraph is grouped together in a single line.\n",
    "4. Blank lines are condensed down into single-newline paragraph breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inFile = open(\"1342-0.txt\", 'r', encoding=\"utf8\") # Here's the raw input file.\n",
    "outFile = open(\"pride_and_prejudice.txt\", 'w', encoding=\"utf8\") # Here's the cleaned input file.\n",
    "all_lines = inFile.readlines()\n",
    "\n",
    "in_header = True # Check whether we're in the header or not.\n",
    "prev = False # Was there text in the previous line? Use to avoid consecutive empty lines.\n",
    "\n",
    "for line in all_lines:\n",
    "    # Process the header and footer.\n",
    "    if in_header:\n",
    "        if line[0:7] == \"Chapter\": # Once we see \"Chapter\", we're past the header.\n",
    "            in_header = False\n",
    "        else: # We're still in the header, so skip to next line.\n",
    "            continue\n",
    "    elif line[0:18] == \"End of the Project\": # Here's the footer, so we're done.\n",
    "        break\n",
    "        \n",
    "    # Get rid of lines starting with multiple spaces (mostly the asterisks).\n",
    "    if line[0:2] == \"  \":\n",
    "        continue\n",
    "    \n",
    "    # If within a paragraph, group all of the sentences together.\n",
    "    if line != '\\n':\n",
    "        line = line.replace('\\n',' ')\n",
    "        outFile.write(line)\n",
    "        prev = True\n",
    "    \n",
    "    # Compress paragraph breaks into single newlines.\n",
    "    elif prev == True:\n",
    "        outFile.write('\\n')\n",
    "        prev = False\n",
    "\n",
    "# Clean up our file handles.\n",
    "inFile.close()        \n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a very simple text prediction model\n",
    "\n",
    "Now we're going to build a Markov chain to do some very simplistic text prediction. First we're going to read the existing text into a Python dictionary. Then we'll use the dictionary to \"predict\" which words follow which other words.\n",
    "\n",
    "There are a couple of interesting notes here:\n",
    "* I keep track of \"first\" words that are used to start paragraphs. These are the starting points for my Markov chains.\n",
    "* I keep track of potential \"title\" words. These are just words starting with the letter 'P'.\n",
    "* I keep quotations and prose in separate dictionaries.\n",
    "* I keep duplicates, so those word combinations will have a higher chance of appearing in my output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp_dict = {} #to hold follow-up words in general prose\n",
    "pp_quote = {} #to hold follow-up words within quotations\n",
    "pp_first = [] #to hold \"first\" words that can be used to start new paragraphs\n",
    "pp_title = {} #to hold potential \"title\" words\n",
    "\n",
    "inFile = open(\"pride_and_prejudice.txt\", 'r', encoding=\"utf8\") # Here's the training data.\n",
    "pp = inFile.readlines()\n",
    "\n",
    "# Load up the dictionaries.\n",
    "for paragraph in pp:\n",
    "    words = paragraph.strip().split() # Convert sentences to lists of words.\n",
    "    len_words = len(words)\n",
    "    if len_words == 0: continue # Don't bother indexing empty paragraphs.\n",
    "    in_quote = False\n",
    "    \n",
    "    # Go from the first to second-to-last word in the paragraph.\n",
    "    for i in range(len(words)-1):\n",
    "        current = words[i]\n",
    "        next = words[i+1]\n",
    "\n",
    "        if i == 0: pp_first.append(current) # Store \"first\" words which can be used to start Markov chains.\n",
    "        \n",
    "        if current[0].upper() == 'P': # If the word starts with 'P' then keep track as a potential \"title\" word.\n",
    "            title_word = current.upper()\n",
    "            while title_word[-1] not in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\": # Get rid of punctuation at end of title words.\n",
    "                title_word = title_word[:-1]\n",
    "            if title_word not in pp_title:\n",
    "                pp_title[title_word] = True\n",
    "        \n",
    "        # Map the current word to its next word(s).\n",
    "        if '“' in current: in_quote = True\n",
    "        if '”' in current: in_quote = False # In case of one-word quotes, this will revert to False.\n",
    "        if in_quote:\n",
    "            if current in pp_quote: pp_quote[current].append(next) # Store \"quotation\" words here.\n",
    "            else: pp_quote[current] = [next]\n",
    "        else:\n",
    "            if current in pp_dict: pp_dict[current].append(next) # Store \"prose\" words here.\n",
    "            else: pp_dict[current] = [next]\n",
    "                \n",
    "inFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text using a Markov chain\n",
    "\n",
    "Now that we've read in the text and created a model for it, we can generate some text. The model does this by looking at the current word, and then randomly picking from the list of all previously seen follow-up words. It isn't very sophisticated and has no sense of context or content, only that the 2-word combination has been seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austen-bot has generated a 54-chapter story.\n"
     ]
    }
   ],
   "source": [
    "outFile = open(\"pp_output.txt\", 'w', encoding=\"utf8\") # Here's the resulting file.\n",
    "\n",
    "# Decide whether to output a full story or just a single paragraph.\n",
    "fullstory = True # Set to False for a single paragraph.\n",
    "chapters = random.randint(1,61) # Our story will have between 1 and 61 chapters.\n",
    "if fullstory:\n",
    "    title_words = random.sample(pp_title.keys(),2)\n",
    "    title = title_words[0]+\" AND \"+title_words[1] # Generate a title for our story.\n",
    "    outFile.write(title.upper()+'\\n'+\"by Austen-bot (https://github.com/AlanAu/Austen-bot)\\n\")\n",
    "    outFile.write('\\nChapter 1\\n')\n",
    "else:\n",
    "    chapters = 1\n",
    "\n",
    "chapter = 1 # We always start at Chapter 1.\n",
    "sentences = False # Check to make sure we have at least 1 sentence in a chapter.\n",
    "in_quote = False # Use this to decide whether to pull from the \"quote\" words or the \"prose\" words.\n",
    "while chapter <= chapters:\n",
    "    start = random.sample(pp_first,1) # Pick a random starting word for our next paragraph.\n",
    "    if '“' in start[0]: in_quote = True\n",
    "    if '”' in start[0]: in_quote = False\n",
    "    output = [start[0]]\n",
    "    \n",
    "    # Check to see if we're trying to start a new chapter.\n",
    "    if start[0] == \"Chapter\":\n",
    "        if not sentences: continue # Make sure there's at least 1 sentence in the chapter.\n",
    "        chapter += 1\n",
    "        sentences = False\n",
    "        if chapter > chapters: # Stop when we would have gone beyond the last chapter.\n",
    "            break\n",
    "        output.append(str(chapter))\n",
    "    \n",
    "    # Generate a new paragraph.\n",
    "    else:\n",
    "        sentences = True\n",
    "        current = start[0]\n",
    "        while True:\n",
    "            # We're in a quote, so pull from pp_quote.\n",
    "            if in_quote and current in pp_quote:\n",
    "                next = random.sample(pp_quote[current],1)\n",
    "            # We're not in a quote, so pull from pp_dict.\n",
    "            elif current in pp_dict:\n",
    "                next = random.sample(pp_dict[current],1)\n",
    "            else:\n",
    "                if in_quote: # Close any unclosed quotes.\n",
    "                    in_quote = False\n",
    "                    output[-1] = output[-1]+'”'\n",
    "                break\n",
    "            output.append(next[0])\n",
    "            current = next[0]\n",
    "            if '“' in current: in_quote = True\n",
    "            if '”' in current: in_quote = False\n",
    "    outFile.write('\\n'+' '.join(output)+'\\n')\n",
    "\n",
    "outFile.close()\n",
    "print(\"Austen-bot has generated a \"+str(chapters)+\"-chapter story.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
